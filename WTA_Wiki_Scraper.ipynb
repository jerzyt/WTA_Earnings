{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "tired-monte",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import requests\n",
    "\n",
    "ROW_LOOKUP = {\n",
    "    'CountryWiki': 'Country',\n",
    "    'Born': 'Born',\n",
    "    'Height': 'Height',\n",
    "    'TurnedPro': 'Turned.*pro',\n",
    "    'Retired': 'Retired',\n",
    "    'Coach': 'Coach',\n",
    "    'EarningsWiki': 'Prize.*money',\n",
    "    'CareerRecord': 'Career.*record',\n",
    "    'Titles': 'Career.*titles',\n",
    "    'HighRank': 'Highest.*ranking',\n",
    "    }\n",
    "\n",
    "BAD_URLS = []\n",
    "\n",
    "PLAYERS_INFO = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "least-separate",
   "metadata": {},
   "outputs": [],
   "source": [
    "urls = [\n",
    "    #'https://en.wikipedia.org/wiki/Asdf_Xyz',\n",
    "    'https://en.wikipedia.org/wiki/Serena_Williams',\n",
    "    #'https://en.wikipedia.org/wiki/Venus_Williams',\n",
    "    'https://en.wikipedia.org/wiki/Simona_Halep',\n",
    "    #'https://en.wikipedia.org/wiki/Maria_Sharapova',\n",
    "    #'https://en.wikipedia.org/wiki/Caroline_Wozniacki',\n",
    "    #'https://en.wikipedia.org/wiki/Victoria_Azarenka',\n",
    "    #'https://en.wikipedia.org/wiki/Petra_Kvitova',\n",
    "    #'https://en.wikipedia.org/wiki/Angelique_Kerber',\n",
    "    #'https://en.wikipedia.org/wiki/Agnieszka_Radwanska',\n",
    "    #'https://en.wikipedia.org/wiki/Svetlana_Kuznetsova',\n",
    "    #'https://en.wikipedia.org/wiki/Martina_Hingis',\n",
    "    #'https://en.wikipedia.org/wiki/Garbine_Muguruza',\n",
    "    #'https://en.wikipedia.org/wiki/Kim_Clijsters',\n",
    "    #'https://en.wikipedia.org/wiki/Karolina_Pliskova',\n",
    "    #'https://en.wikipedia.org/wiki/Ashleigh_Barty',\n",
    "    #'https://en.wikipedia.org/wiki/Lindsay_Davenport',\n",
    "    #'https://en.wikipedia.org/wiki/Steffi_Graf',\n",
    "    #'https://en.wikipedia.org/wiki/Martina_Navratilova',\n",
    "    #'https://en.wikipedia.org/wiki/Elina_Svitolina',\n",
    "    #'https://en.wikipedia.org/wiki/Naomi_Osaka',\n",
    "    #'https://en.wikipedia.org/wiki/Justine_Henin',\n",
    "    #'https://en.wikipedia.org/wiki/Samantha_Stosur',\n",
    "    #'https://en.wikipedia.org/wiki/Jelena_Jankovic',\n",
    "    #'https://en.wikipedia.org/wiki/Iga_Swiatek',\n",
    "    #'https://en.wikipedia.org/wiki/Cori_Gauff',\n",
    "    #'https://en.wikipedia.org/wiki/Emma_Raducanu',\n",
    "    'https://en.wikipedia.org/wiki/Qiang_Wang',\n",
    "    'https://en.wikipedia.org/wiki/Anna_Kournikova',\n",
    "    'https://en.wikipedia.org/wiki/Denise_Starr',\n",
    "    'https://en.wikipedia.org/wiki/Kai-Chen_Chang',\n",
    "    'https://en.wikipedia.org/wiki/Marie-Gayanay_Mikaelian',\n",
    "    ]\n",
    "\n",
    "def get_urls_from_list():\n",
    "    for url in urls:\n",
    "        yield url"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "educated-brooklyn",
   "metadata": {},
   "source": [
    "The table needs to be navigated by looping through the data frame rows and the looping needs to abort once the value 'Doubles' is encountered.  Otherwise, looping by lookup of the Attr names returns dataframes if the same attribute is found multiple times."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "medieval-listening",
   "metadata": {},
   "source": [
    "OK, got the proper subset of the data table (sub_tab), but still having problem with extracting the cell values.\n",
    "What next?\n",
    "Need the following to extract a value of the cell:  \n",
    "sub_tab.loc[sub_tab.index[4], 'Value']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "macro-measure",
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_data_items(sub_tab):\n",
    "    info = {}\n",
    "    for key in ROW_LOOKUP.keys():\n",
    "        #print(key)\n",
    "        val = ROW_LOOKUP[key]\n",
    "        #print(val)\n",
    "        if len(sub_tab[sub_tab['Attr'].str.contains(val, regex=True, na=False)]) > 0:\n",
    "            row_idx = sub_tab[sub_tab['Attr'].str.contains(val, regex=True, na=False)].index[0]\n",
    "            #print(sub_tab.loc[sub_tab.index[row_idx], 'Value'])\n",
    "            info[key] = sub_tab.loc[sub_tab.index[row_idx], 'Value']\n",
    "\n",
    "    return info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "compact-utility",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_singles_subtable(table):\n",
    "    doubles_idx = table.index[table['Attr'] == 'Doubles'].to_list()\n",
    "    #print(doubles_idx)\n",
    "    if len(doubles_idx) > 0:\n",
    "        sub_tab = table[:doubles_idx[0]]\n",
    "        return sub_tab\n",
    "    else:\n",
    "        return table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "continental-equality",
   "metadata": {},
   "outputs": [],
   "source": [
    "# using requests.get as a workaround in pandas read_html bug which doesn't work with Unicode\n",
    "# https://github.com/pandas-dev/pandas/issues/21499\n",
    "\n",
    "def get_wiki_info(url):\n",
    "    try:\n",
    "        r = requests.get(url)\n",
    "        page = r.text\n",
    "        tables = pd.read_html(page, attrs={'class': 'infobox vcard'})\n",
    "    except:\n",
    "        print('Failed to read url ' + url)\n",
    "        BAD_URLS.append(url)\n",
    "        return\n",
    "\n",
    "    table = tables[0]\n",
    "    (rows, cols) = table.shape\n",
    "    #print(table.shape)\n",
    "    \n",
    "    columns = ['Attr', 'Value']\n",
    "    for i in range(2, cols):\n",
    "        columns.append('Extra_' + str(i))\n",
    "    table.columns = columns\n",
    "    \n",
    "    sub_tab = get_singles_subtable(table)\n",
    "    return find_data_items(sub_tab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "capital-builder",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_urls_from_df():\n",
    "    df = pd.read_pickle('./Data/earnings.pickle')\n",
    "    for i in range(0, len(df)):\n",
    "        url = df.loc[df.index[i], 'WikiLink']\n",
    "        yield url"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "pressed-ending",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from random import random\n",
    "from time import sleep\n",
    "\n",
    "#for url in get_urls_from_list():\n",
    "for url in get_urls_from_df():\n",
    "    print(\"processing: \" + url)\n",
    "    r = random()\n",
    "    sleep(r)\n",
    "    PLAYERS_INFO[url] = get_wiki_info(url)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "preliminary-weekly",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "pi = pd.DataFrame(PLAYERS_INFO).transpose()\n",
    "pi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "false-feeling",
   "metadata": {},
   "outputs": [],
   "source": [
    "pi.to_html('./Data/player_info.html', render_links=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aerial-computer",
   "metadata": {},
   "outputs": [],
   "source": [
    "pi.to_pickle('./Data/player_info.pickle')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "streaming-government",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "print(len(BAD_URLS))\n",
    "file = open('./Data/bad_urls.pickle', 'wb')\n",
    "\n",
    "# dump information to that file\n",
    "pickle.dump(BAD_URLS, file)\n",
    "\n",
    "# close the file\n",
    "file.close()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
